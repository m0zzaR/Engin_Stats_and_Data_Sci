{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ceb2c1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"hw4.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1028bb4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "<h1><center>SDSE Homework 4 <br><br> Text Classification with Naive Bayes </center></h1>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa286eae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-23T20:38:12.672833Z",
     "iopub.status.busy": "2023-10-23T20:38:12.672510Z",
     "iopub.status.idle": "2023-10-23T20:38:13.029272Z",
     "shell.execute_reply": "2023-10-23T20:38:13.028707Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3567ef77",
   "metadata": {},
   "source": [
    "In this homework we will apply the technique of Naive Bayes classification to the problem of categorizing text-based documents. The dataset is a selection of posts from scikit-learn's ['20 newsgroups' dataset](https://scikit-learn.org/stable/datasets/real_world.html#newsgroups-dataset), which contains some 18000 newsgroup posts in 20 different categories, such as politics, autos, electronics, atheism, and hockey. For simplicity, we will focus on just two of the categories: computer graphics and motorcycles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad81cc2",
   "metadata": {},
   "source": [
    "# 0. Load the data\n",
    "\n",
    "The cell below loads the data from a pickle file. The file contains training data `(Xtrain, ytrain)` and validation data `(Xval,yval)`. Each entry in `Xtrain` and `Xval` is a post. The corresponding output in `ytrain` or `yval` is its category.\n",
    "`categories` is the set of all categories.\n",
    "`vocabulary` is the set of feature words.\n",
    "\n",
    "Take a few minutes to familiarize yourself with these variables by inspecting\n",
    "+ the shape of all of the variables\n",
    "+ one of the entries in `Xtrain` and `ytrain` \n",
    "+ the size and contents of `categories` and `vocabulary`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ab1037",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-23T20:38:13.031824Z",
     "iopub.status.busy": "2023-10-23T20:38:13.031586Z",
     "iopub.status.idle": "2023-10-23T20:38:13.101654Z",
     "shell.execute_reply": "2023-10-23T20:38:13.101118Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('hw4_text.pickle','rb') as file:\n",
    "    Xtrain, ytrain, Xval, yval, categories, vocabulary = pickle.load(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a27adf6",
   "metadata": {},
   "source": [
    "# 1. Define constants\n",
    "\n",
    "Define the following variables in terms of quantities loaded from the pickle file. \n",
    "+ `N` ... number of documents in the training corpus\n",
    "+ `K` ... number of document categories\n",
    "+ `D` ... number of words in the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b73198",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-23T20:38:13.104580Z",
     "iopub.status.busy": "2023-10-23T20:38:13.104390Z",
     "iopub.status.idle": "2023-10-23T20:38:13.110255Z",
     "shell.execute_reply": "2023-10-23T20:38:13.109823Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "N = ...\n",
    "K = ...\n",
    "D = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcbd2fc",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51ab29c",
   "metadata": {},
   "source": [
    "# 2. Find the number of training documents for each category\n",
    "\n",
    "Create a dictionary called `docs_per_category` that stores the number of documents in the training data under each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4e750c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-23T20:38:13.131366Z",
     "iopub.status.busy": "2023-10-23T20:38:13.131190Z",
     "iopub.status.idle": "2023-10-23T20:38:13.135349Z",
     "shell.execute_reply": "2023-10-23T20:38:13.134844Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "docs_per_category = dict.fromkeys(categories,0)\n",
    "for category in categories:\n",
    "    docs_per_category[category] = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a39765",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb3af8e",
   "metadata": {},
   "source": [
    "# 3. Bag-of-words representation\n",
    "\n",
    "Our Naive Bayes model will operate on a bag-of-words representation of each document. A bag-of-words representation is simply a set with all of the individual words of the document that are also in the vocabulary. The first task is to write the `to_bow` method, which converts a document into its bag-of-words. \n",
    "\n",
    "The arguments for this method are the document as a string and the vocabulary. It should return a set (`bow`) with the unique words that appear in both the document and the vocabulary. The comments in the method provide steps to follow.\n",
    "\n",
    "**Hints**\n",
    "+ The `set` constructor\n",
    "+ The `add` method on sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db01b3e6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-23T20:38:13.149948Z",
     "iopub.status.busy": "2023-10-23T20:38:13.149704Z",
     "iopub.status.idle": "2023-10-23T20:38:13.155658Z",
     "shell.execute_reply": "2023-10-23T20:38:13.155140Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def to_bow(doc,vocabulary):\n",
    "    bow = set()\n",
    "    \n",
    "    # Split `doc` at spaces using the the string's `split` method. Obtain a list of strings.\n",
    "    words_list = ...\n",
    "\n",
    "    # Keep only unique words from the list, by casting it as a set.\n",
    "    word_set = ...\n",
    "\n",
    "    # From that set, store in bow only the ones that are present in the vocabulary.\n",
    "    ...\n",
    "\n",
    "    return bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d60aaaf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-23T20:38:13.157774Z",
     "iopub.status.busy": "2023-10-23T20:38:13.157573Z",
     "iopub.status.idle": "2023-10-23T20:38:13.170668Z",
     "shell.execute_reply": "2023-10-23T20:38:13.170065Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run `to_bow` on every document in `Xtrain`.\n",
    "Xtrain_bow = np.array([to_bow(doc,vocabulary) for doc in Xtrain])\n",
    "bag_sizes = np.array([len(Xtrain_bow[i]) for i in range(len(Xtrain_bow))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79a6cc0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "439199d7",
   "metadata": {},
   "source": [
    "# 4. Compute the document count for each word in each category\n",
    "To estimate the parameters of the Naive Bayes model, we will need to know, for each category and each word, the number of documents of the category that contain the word. Implement the `find_doc_counts_per_word_category` following the steps provided in the code. This function accepts training data (`Xtrain_bow` and ` ytrain`), as well as the categories and vocabulary. It produces `doc_counters`, which is a dictionary indexed by category. For each category, `doc_counters[category]` is a dictionary indexed by words in the vocabulary. For each `word` in the vocabulary, `doc_counters[category][word]` is the number of documents of that category that contain that word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1926115",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-23T20:38:13.197968Z",
     "iopub.status.busy": "2023-10-23T20:38:13.197533Z",
     "iopub.status.idle": "2023-10-23T20:38:13.202963Z",
     "shell.execute_reply": "2023-10-23T20:38:13.202362Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_doc_counts_per_word_category(categories,vocabulary,ytrain,Xtrain_bow):\n",
    "\n",
    "    # Initialize doc_counters\n",
    "    doc_counters = dict.fromkeys(categories)\n",
    "    for category in categories:\n",
    "        doc_counters[category]  = dict.fromkeys(vocabulary,0)\n",
    "\n",
    "    # Loop through categories.\n",
    "    for category in categories:\n",
    "\n",
    "        # Filter Xtrain_bow and keep only the documents of this category\n",
    "        docs_in_category = ...\n",
    "\n",
    "        # For each document in this category, increment the doc_counter entry for all vocabulary words found in the document.\n",
    "        ...\n",
    "\n",
    "    return doc_counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd8dcee",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-23T20:38:13.205164Z",
     "iopub.status.busy": "2023-10-23T20:38:13.204936Z",
     "iopub.status.idle": "2023-10-23T20:38:13.209613Z",
     "shell.execute_reply": "2023-10-23T20:38:13.209040Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run `find_doc_counts_per_word_category`\n",
    "doccount_per_cat_and_word = find_doc_counts_per_word_category(categories,vocabulary,ytrain,Xtrain_bow)\n",
    "testwords = ['according','between','could','explain','harley','miles','source','wondering']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d89590",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b757aad",
   "metadata": {},
   "source": [
    "# 5. Find word frequencies per category\n",
    "\n",
    "Write the `compute_freq` method. This method takes `doccount_per_cat_and_word`, `ytrain` and the Laplace smoothing factor `alpha` as inputs and computes word and category frequencies.\n",
    "\n",
    "+ Category frequencies `catfreq[category]`: The category frequency for category $c$ is the proportion of the documents that are of class $c$.\n",
    "\n",
    "$$\\hat{p}_c = \\frac{N_c}{N} $$\n",
    "\n",
    "where $N_c$ is the number of documents in category $c$, and $N$ is the total number of documents. \n",
    "\n",
    "+ Word frequencies `wordfreq[category][word]`: The Laplace-smoothed word frequency for a word $d$ and category $k$.\n",
    "\n",
    "$$\\hat{p}_{d,c} = \\frac{N_{d,c}+\\alpha}{N_c + \\alpha K} $$\n",
    "\n",
    "where $N_{d,c}$ is the number of documents of category $c$ that contain word $d$, and $\\alpha$ is the Laplace smoothing factor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fde92ec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-23T20:38:13.223983Z",
     "iopub.status.busy": "2023-10-23T20:38:13.223799Z",
     "iopub.status.idle": "2023-10-23T20:38:13.230993Z",
     "shell.execute_reply": "2023-10-23T20:38:13.230494Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_freq(doccount_per_cat_and_word,ytrain,categories,vocabulary,alpha):\n",
    "\n",
    "    K = len(categories)  # number of categories\n",
    "    D = len(vocabulary)  # number of vocabulary words\n",
    "    N = len(ytrain)      # number of documents\n",
    "\n",
    "    # Compute the number of documents in each category. Store it in the dictionary `ndocs`.\n",
    "    ndocs = dict.fromkeys(categories)\n",
    "    for category in categories:\n",
    "        ndocs[category] = ...\n",
    "\n",
    "    # Compute the category frequenies. For each category, catfreq[category] equals\n",
    "    # the number of documents of that category (ndocs) divided by the total number of documents.\n",
    "    catfreq = dict()\n",
    "    for category, n in ndocs.items():\n",
    "        catfreq[category] = ...\n",
    "\n",
    "    # Initialize wordfreq\n",
    "    wordfreq = dict.fromkeys(categories)\n",
    "    for category in categories:\n",
    "        wordfreq[category] = dict.fromkeys(vocabulary)\n",
    "\n",
    "    # Compute wordfreq\n",
    "    # For each category ...\n",
    "    for category in categories:\n",
    "\n",
    "        # the denominator is the number of documents in that category + alpha*K\n",
    "        den = ...\n",
    "\n",
    "        # iterate through items in `doccount_per_cat_and_word` to compute\n",
    "        # the word frequency for every category and word.\n",
    "        for word, doccount in doccount_per_cat_and_word[category].items():\n",
    "            wordfreq[category][word] = ...\n",
    "\n",
    "    return wordfreq, catfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40534d05",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-23T20:38:13.232942Z",
     "iopub.status.busy": "2023-10-23T20:38:13.232751Z",
     "iopub.status.idle": "2023-10-23T20:38:13.236364Z",
     "shell.execute_reply": "2023-10-23T20:38:13.235780Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run `compute_word_log_freq` with $\\alpha=0.01$.\n",
    "wordfreq, catfreq = compute_freq(doccount_per_cat_and_word,ytrain,categories,vocabulary,0.01)\n",
    "testwords = ['according','between','could','explain','harley','miles','source','wondering']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5055ac9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb52b676",
   "metadata": {},
   "source": [
    "# 6. Write the Naive Bayes prediction function.\n",
    "\n",
    "Use your Naive Bayes model to predict the category of a given test document `doc`. \n",
    "\n",
    "Recall that Naive Bayes selects the category as follows:\n",
    "\n",
    "$$\\hat{y} = \\underset{c}{\\text{argmax}} \\hspace{2mm} \\log \\hat{p}_c +   \\sum_{d:x^d=1}  \\log \\hat{p}_{d,c} +\\sum_{d:x^d=0}  \\log (1-\\hat{p}_{d,c})$$\n",
    "\n",
    "The arguments of the `predict` method are:\n",
    "+ `doc`: a single document as a string.\n",
    "+ `wordfreq`, `catfreq`: the ratios computed in the previous step (with $\\alpha=0.01$)\n",
    "+ `vocabulary`: the vocabulary.\n",
    "\n",
    "The steps are:\n",
    "1. Find the BOW representation of `doc`.\n",
    "\n",
    "2. Loop through categories, for each one compute its score using the above formula.\n",
    "\n",
    "3. Return the category with the highest score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7779c116",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-23T20:38:13.258431Z",
     "iopub.status.busy": "2023-10-23T20:38:13.258249Z",
     "iopub.status.idle": "2023-10-23T20:38:13.263751Z",
     "shell.execute_reply": "2023-10-23T20:38:13.263256Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict(doc, wordfreq, catfreq, vocabulary):\n",
    "\n",
    "    # 1. Find the BOW representation of doc.\n",
    "    doc_bow = ...\n",
    "\n",
    "    # 2. Loop through categories, for each one compute its score, and save it in score_cat.\n",
    "    score_cat = dict.fromkeys(categories,0)\n",
    "    for category in categories:\n",
    "        score = ...\n",
    "        ...\n",
    "\n",
    "        score_cat[category] = score\n",
    "\n",
    "    # 3. Find the category with the highest score.\n",
    "    maxcat = ...\n",
    "\n",
    "    return maxcat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cdb8bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-23T20:38:13.265654Z",
     "iopub.status.busy": "2023-10-23T20:38:13.265457Z",
     "iopub.status.idle": "2023-10-23T20:38:13.957463Z",
     "shell.execute_reply": "2023-10-23T20:38:13.956880Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "allpred = [predict(Xt, wordfreq, catfreq, vocabulary) for Xt in Xval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93be312",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2275ea9c",
   "metadata": {},
   "source": [
    "# 7. Compute the accuracy of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02984f4d",
   "metadata": {},
   "source": [
    "The function `compute_accuracy` takes a dataset (`X`,`y`), computes predictions using the `predict` function, and computes the accuracy of these predictions with respect to `y`. The accuracy of the model is defined as the number of correct predictions, divided by the total number of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3524c95f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-23T20:38:13.966316Z",
     "iopub.status.busy": "2023-10-23T20:38:13.966145Z",
     "iopub.status.idle": "2023-10-23T20:38:13.970566Z",
     "shell.execute_reply": "2023-10-23T20:38:13.970054Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(X, y, wordfreq, catfreq, vocabulary):\n",
    "\n",
    "    # count the number of correct predictions\n",
    "    correct = 0\n",
    "    for i in ...\n",
    "\n",
    "    # accuracy is the ratio of correct predictions to total predictions.\n",
    "    accuracy = ...\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36bca9ac",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcec403",
   "metadata": {},
   "source": [
    "# 8. Optimize the Laplace smoothing factor."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8763413e",
   "metadata": {},
   "source": [
    "## 8.1. Train the model and compute its accuracy for logarithmically spaced values of $\\alpha$ ranging from $10^{-3}$ to $10^1$\n",
    "\n",
    "Here 'training the model' means computing the probability estimates with `compute_freq` with the training data. Do this for the given range of $\\alpha$'s. Compute and store the accuracy of each of these models using the validation data. \n",
    "\n",
    "**Hint**: Python's `enumerate` method can be used to produce both indices `i` and values `alpha` when iterating through `alphas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bfd008",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-23T20:38:14.044395Z",
     "iopub.status.busy": "2023-10-23T20:38:14.044084Z",
     "iopub.status.idle": "2023-10-23T20:38:26.415314Z",
     "shell.execute_reply": "2023-10-23T20:38:26.414775Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "alphas = np.logspace(-3,1,20)\n",
    "acc = np.empty(len(alphas))\n",
    "for i, alpha in enumerate(alphas):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a2bb85",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q8p1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ca432b",
   "metadata": {},
   "source": [
    "## 8.2. Plot the accuracies as a function of $\\alpha$ using `plt.semilogx`\n",
    "\n",
    "Your plot should look like this:\n",
    "\n",
    "<img src=\"f1.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f7829a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-23T20:38:26.425040Z",
     "iopub.status.busy": "2023-10-23T20:38:26.424839Z",
     "iopub.status.idle": "2023-10-23T20:38:26.809941Z",
     "shell.execute_reply": "2023-10-23T20:38:26.809407Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2563505",
   "metadata": {},
   "source": [
    "## 8.3. Find the optimal $\\alpha$ and its corresponding validation accuracy\n",
    "\n",
    "**Hint**: [np.argmax](https://numpy.org/doc/stable/reference/generated/numpy.argmax.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafc0059",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-23T20:38:26.812446Z",
     "iopub.status.busy": "2023-10-23T20:38:26.812259Z",
     "iopub.status.idle": "2023-10-23T20:38:26.816068Z",
     "shell.execute_reply": "2023-10-23T20:38:26.815640Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bestind = ...\n",
    "best_acc = ...\n",
    "best_alpha = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2f3e3a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q8p3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db12cf2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe874ee",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ad3129",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3b8b5ce4b1bd0cdb09a48c826d4154f25cb98d27fcdd75ace86cf123225b5557"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q1": {
     "name": "q1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> N==60\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> K==2\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        },
        {
         "code": ">>> D==548\nTrue",
         "hidden": false,
         "locked": false,
         "points": 1
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> docs_per_category['rec.motorcycles']==35\nTrue",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> docs_per_category['comp.graphics']==25\nTrue",
         "hidden": false,
         "locked": false,
         "points": 2
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> Xtrain_bow[23]=={'a',\n...                  'and',\n...                  'answer',\n...                  'bad',\n...                  'but',\n...                  'find',\n...                  'for',\n...                  'here',\n...                  'i',\n...                  'if',\n...                  'in',\n...                  'is',\n...                  'it',\n...                  'maybe',\n...                  'my',\n...                  'not',\n...                  'of',\n...                  'posting',\n...                  'sorry',\n...                  'the',\n...                  'thing',\n...                  'this',\n...                  'try',\n...                  'use',\n...                  'will',\n...                  'work',\n...                  'your'}\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> Xtrain_bow[34]=={'a',\n...                  'about',\n...                  'an',\n...                  'and',\n...                  'are',\n...                  'be',\n...                  'by',\n...                  'can',\n...                  'do',\n...                  'down',\n...                  'exhaust',\n...                  'for',\n...                  'gas',\n...                  'guess',\n...                  'have',\n...                  'i',\n...                  'in',\n...                  'is',\n...                  'like',\n...                  'line',\n...                  'may',\n...                  'not',\n...                  'on',\n...                  'only',\n...                  'out',\n...                  'really',\n...                  'seems',\n...                  'some',\n...                  'that',\n...                  'the',\n...                  'think',\n...                  'to',\n...                  'understand',\n...                  'we',\n...                  'will',\n...                  'would'}\nTrue",
         "hidden": false,
         "locked": false,
         "points": 3
        },
        {
         "code": ">>> np.all(bag_sizes == np.array([38, 40, 41, 40, 38, 32, 25, 38, 33, 45, 34, 36, 42, 30, 48, 36, 38,\n...                               34, 56, 31, 35, 35, 29, 27, 41, 44, 29, 41, 43, 38, 40, 45, 28, 35,\n...                               36, 17, 38, 47, 34, 45, 32, 48, 48, 40, 48, 40, 53, 34, 32, 39, 31,\n...                               39, 45, 57, 40, 26, 37, 36, 38, 33]))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 3
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> [doccount_per_cat_and_word['comp.graphics'][word] for word in testwords]==[1, 2, 3, 1, 0, 0, 1, 1]\nTrue",
         "hidden": false,
         "locked": false,
         "points": 3
        },
        {
         "code": ">>> [doccount_per_cat_and_word['rec.motorcycles'][word] for word in testwords]==[2, 1, 3, 0, 3, 0, 0, 0]\nTrue",
         "hidden": false,
         "locked": false,
         "points": 3
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5": {
     "name": "q5",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isclose(catfreq['comp.graphics'], 0.4166666666666667, atol=1e-2) \nTrue",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> np.all(np.isclose([wordfreq['rec.motorcycles'][word] for word in testwords] ,\n...        [0.05739577384351798,0.028840662478583665,0.0859508852084523,0.00028555111364934324,0.0859508852084523,0.00028555111364934324,0.00028555111364934324,0.00028555111364934324]   , atol=1e-2))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 3
        },
        {
         "code": ">>> np.all(np.isclose([wordfreq['comp.graphics'][word] for word in testwords],\n...                   [0.04036770583533174,0.08033573141486809,0.12030375699440447,0.04036770583533174,0.0003996802557953637,0.0003996802557953637,0.04036770583533174,0.04036770583533174], atol=1e-2))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6": {
     "name": "q6",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> \n>>> allpred[20:50:2]==['rec.motorcycles',\n...  'rec.motorcycles',\n...  'rec.motorcycles',\n...  'rec.motorcycles',\n...  'rec.motorcycles',\n...  'comp.graphics',\n...  'comp.graphics',\n...  'rec.motorcycles',\n...  'comp.graphics',\n...  'rec.motorcycles',\n...  'rec.motorcycles',\n...  'comp.graphics',\n...  'rec.motorcycles',\n...  'comp.graphics',\n...  'rec.motorcycles']\nTrue",
         "hidden": false,
         "locked": false,
         "points": 4
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7": {
     "name": "q7",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isclose(compute_accuracy(Xtrain, ytrain, wordfreq, catfreq, vocabulary),1.0,atol=1e-3)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 2
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q8p1": {
     "name": "q8p1",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.all(np.isclose(acc,[0.84912281, 0.84912281, 0.85087719, 0.85263158, 0.85438596,\n...        0.85438596, 0.85789474, 0.85789474, 0.85789474, 0.86140351,\n...        0.86666667, 0.87017544, 0.87368421, 0.85614035, 0.80701754,\n...        0.71052632, 0.63157895, 0.61754386, 0.60877193, 0.60175439],atol=1e-3))\nTrue",
         "hidden": false,
         "locked": false,
         "points": 3
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q8p3": {
     "name": "q8p3",
     "points": null,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> np.isclose(best_acc,0.8736842105263158,atol=1e-2)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 2
        },
        {
         "code": ">>> np.isclose(best_alpha,0.3359818286283781,atol=1e-2)\nTrue",
         "hidden": false,
         "locked": false,
         "points": 2
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
